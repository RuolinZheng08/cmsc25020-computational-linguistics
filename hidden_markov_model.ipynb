{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Two-State HMM: Vowels and Consonants\n",
    "## Part 1.\n",
    "1. Code for setting up the states.\n",
    "2. Initialize A,B,Pi as distributions. \n",
    "3. Calculate alpha and beta.\n",
    "4. Calculate the probability of each word in two ways so they match\n",
    "\n",
    "## Part 2. Expectation & Part 3. Maximization\n",
    "### Training objective: minimize total plog (negative base-2 log)\n",
    "1. Calculate the soft (or expected) count of each letter.\n",
    "2. Set up tables for soft counts in general, and word-initially\n",
    "3. Recomputing A, B, and Î .\n",
    "4. Putting expectation and maximization into a loop sensibly, with a stop condition that makes sense.\n",
    "5. Show the preference of each letter for one of the states by computing the log ratios of the emission proabilities\n",
    "6. Determine the values of A for the best analysis (highest probability) of the English data.\n",
    "\n",
    "## Part 4. Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(25020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file):\n",
    "    with open(file, 'rt') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.rstrip() + '#' for line in lines]\n",
    "    return lines\n",
    "\n",
    "def create_lookup(corpus):\n",
    "    alphabet = set()\n",
    "    for word in corpus:\n",
    "        alphabet.update(list(word))\n",
    "    idx_to_char_dict = sorted(alphabet)\n",
    "    char_to_idx_dict = {char: idx for idx, char in enumerate(idx_to_char_dict)}\n",
    "    return idx_to_char_dict, char_to_idx_dict\n",
    "\n",
    "# encode and decode sequence\n",
    "def encode(lookup, seq):\n",
    "    ret = np.array([lookup[char] for char in seq]) # an idx array\n",
    "    return ret\n",
    "\n",
    "def decode(lookup, indices):\n",
    "    ret = [lookup[idx] for indx in indices]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, num_states, num_emissions):\n",
    "        self.num_states = num_states\n",
    "        self.num_emissions = num_emissions\n",
    "        \n",
    "        self.pi = np.random.random(num_states).astype('float128')\n",
    "        self.A = np.random.random((num_states, num_states)).astype('float128')\n",
    "        self.B = np.random.random((num_emissions, num_states)).astype('float128')\n",
    "        # normalize probabilities\n",
    "        self.pi /= self.pi.sum() # sum up to 1\n",
    "        self.A /= self.A.sum(axis=1) # row summing to 1\n",
    "        self.B /= self.B.sum(axis=0) # col summing to 1\n",
    "        \n",
    "        self.alpha = None\n",
    "        self.beta = None\n",
    "        self.xi = None\n",
    "        \n",
    "        self.plog = 0\n",
    "        \n",
    "    def train(self, seqs):\n",
    "        self.plog = 0\n",
    "        self.pi_update = np.zeros(self.num_states)\n",
    "        self.A_update = np.zeros((self.num_states, self.num_states)) \n",
    "        self.B_update = np.zeros((self.num_emissions, self.num_states))\n",
    "        num_seq = 0\n",
    "        for seq in seqs:\n",
    "            self.expectation(seq)\n",
    "            self.maximization(seq)\n",
    "            num_seq += 1\n",
    "        # acutally apply the maximization updates\n",
    "        self.pi = self.pi_update / num_seq\n",
    "        self.A = self.A_update / num_seq\n",
    "        self.B = self.B_update / num_seq\n",
    "\n",
    "        return self.plog\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        T = seq.shape[0]\n",
    "        self.alpha = np.empty((T, self.num_states), dtype='float128') # T * num_states\n",
    "        self.alpha[0] = self.pi * self.B[seq[0]]\n",
    "        for t in range(1, T):\n",
    "            self.alpha[t] = self.alpha[t - 1] @ self.A * self.B[seq[t]]\n",
    "    \n",
    "    def backward(self, seq):\n",
    "        num_states = self.A.shape[0]\n",
    "        T = seq.shape[0]\n",
    "        self.beta = np.empty((T, self.num_states), dtype='float128')\n",
    "        self.beta[T - 1] = 1\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            self.beta[t] = self.A * self.B[seq[t + 1]] @ self.beta[t + 1]\n",
    "            \n",
    "    def alpha_prob(self):\n",
    "        return sum(self.alpha[-1])\n",
    "    \n",
    "    def beta_prob(self, seq):\n",
    "        return sum(self.pi * self.B[seq[0]] * self.beta[0])\n",
    "    \n",
    "    def expectation(self, seq):\n",
    "        self.forward(seq)\n",
    "        self.backward(seq)\n",
    "        self.plog += -np.log2(self.alpha_prob())\n",
    "\n",
    "        T = seq.shape[0]\n",
    "        alpha_p = self.alpha_prob()\n",
    "        self.xi = np.empty((T - 1, self.num_states, self.num_states))\n",
    "        for t in range(T - 1):\n",
    "            for i in range(self.num_states):\n",
    "                for j in range(self.num_states):\n",
    "                    numerator = self.alpha[t, i] * self.A[i, j] * \\\n",
    "                    self.B[seq[t + 1], j] * self.beta[t + 1, j]\n",
    "                    self.xi[t, i, j] = numerator\n",
    "        self.xi /= self.alpha_prob()\n",
    "        \n",
    "        self.gamma = self.alpha * self.beta / alpha_p\n",
    "    \n",
    "    def maximization(self, seq):\n",
    "        # record updates based on expectations\n",
    "        # update pi\n",
    "        self.pi_update += self.gamma[0] # soft counts of each state at time 1\n",
    "        # update A\n",
    "        numerator = self.xi.sum(axis=0) # soft counts of transitions from i to j\n",
    "        denom = self.gamma[:-1].sum(axis=0) # soft counts of transitions out of i\n",
    "        self.A_update += numerator / denom[:, None]\n",
    "        # update B\n",
    "        temp = np.empty((self.num_emissions, self.num_states), dtype='float128')\n",
    "        for k in range(self.num_emissions):\n",
    "            temp[k] = self.gamma[seq == k].sum(axis=0)\n",
    "        self.B_update += temp / denom\n",
    "        \n",
    "    def check_probabilities(self):\n",
    "        assert np.isclose(self.pi.sum(), 1)\n",
    "        assert np.allclose(self.A.sum(axis=1), 1)\n",
    "        assert np.allclose(self.B.sum(axis=0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = read_corpus('english1000.txt')\n",
    "idx_to_char_dict, char_to_idx_dict = create_lookup(corpus)\n",
    "num_states = 2\n",
    "hmm = HMM(num_states, len(idx_to_char_dict))\n",
    "seqs = [encode(char_to_idx_dict, word) for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 21255.84677914975057\n",
      "10 20974.924591172671525\n",
      "20 20705.860612535165309\n",
      "30 20445.523412779754727\n",
      "40 20192.27068334245386\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    plog = hmm.train(seqs)\n",
    "    if i % 10 == 0:\n",
    "        print(i, plog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
